| CONCEPT        | SQL                         | PANDAS                    | SQL EXAMPLE                 | PANDAS EXAMPLE                                   |               |               |
| -------------- | --------------------------- | ------------------------- | --------------------------- | ------------------------------------------------ | ------------- | ------------- |
| FROM           | `FROM t`                    | `df`                      | `FROM users`                | `df`                                             |               |               |
| SELECT         | `SELECT a,b`                | `df[["a","b"]]`           | `SELECT id,name FROM t`     | `df[["id","name"]]`                              |               |               |
| WHERE          | `WHERE a>10`                | `df[df["a"]>10]`          | `WHERE age>18`              | `df[df["age"]>18]`                               |               |               |
| WHERE AND      | `AND`                       | `&`                       | `a=1 AND b=2`               | `(df["a"]==1)&(df["b"]==2)`                      |               |               |
| WHERE OR       | `OR`                        | `                         | `                           | `a=1 OR b=2`                                     | `(df["a"]==1) | (df["b"]==2)` |
| SELECT + WHERE | `SELECT a FROM t WHERE b>5` | `df.loc[df["b"]>5,["a"]]` | `SELECT name WHERE age>30`  | `df.loc[df["age"]>30,["name"]]`                  |               |               |
| LENGTH         | `LENGTH`                    | `len()`                   | `length()`                  | `df[df["name"].str.len()]`                       |               |               |
| LIKE START     | `LIKE 'A%'`                 | `startswith()`            | `name LIKE 'A%'`            | `df[df["name"].str.startswith("A")]`             |               |               |
| LIKE END       | `LIKE '%son'`               | `endswith()`              | `LIKE '%son'`               | `df[df["name"].str.endswith("son")]`             |               |               |
| LIKE CONTAINS  | `LIKE '%an%'`               | `contains()`              | `LIKE '%an%'`               | `df[df["name"].str.contains("an")]`              |               |               |
| NOT LIKE       | `NOT LIKE`                  | `~contains()`             | `NOT LIKE '%x%'`            | `df[~df["name"].str.contains("x")]`              |               |               |
| DISTINCT       | `SELECT DISTINCT a`         | `drop_duplicates()`       | `DISTINCT city`             | `df[["city"]].drop_duplicates()`                 |               |               |
| COUNT DISTINCT | `COUNT(DISTINCT id)`        | `nunique()`               | `COUNT(DISTINCT user_id)`   | `df["user_id"].nunique()`                        |               |               |
| ORDER BY ASC   | `ORDER BY a`                | `sort_values()`           | `ORDER BY salary`           | `df.sort_values("salary")`                       |               |               |
| ORDER BY DESC  | `ORDER BY a DESC`           | `ascending=False`         | `ORDER BY salary DESC`      | `df.sort_values("salary",False)`                 |               |               |
| ORDER MULTI    | `ORDER BY a,b DESC`         | `ascending=[..]`          | `ORDER BY dept,salary DESC` | `df.sort_values(["dept","salary"],[True,False])` |               |               |
| GROUP BY       | `GROUP BY a`                | `groupby()`               | `GROUP BY dept`             | `df.groupby("dept")`                             |               |               |
| AGG SUM        | `SUM(x)`                    | `("x","sum")`             | `SUM(sales)`                | `.agg(total=("sales","sum"))`                    |               |               |
| AGG AVG        | `AVG(x)`                    | `("x","mean")`            | `AVG(price)`                | `("price","mean")`                               |               |               |
| AGG MIN        | `MIN(x)`                    | `("x","min")`             | `MIN(price)`                | `("price","min")`                                |               |               |
| AGG MAX        | `MAX(x)`                    | `("x","max")`             | `MAX(price)`                | `("price","max")`                                |               |               |
| GROUP AGG      | `GROUP BY`                  | `agg()`                   | see below                   | see below                                        |               |               |
| HAVING         | `HAVING SUM(x)>100`         | filter agg                | `HAVING SUM(amt)>100`       | `agg[agg["sum"]>100]`                            |               |               |
| JOIN           | `JOIN`                      | `merge()`                 | `JOIN b ON id`              | `df.merge(df2,on="id")`                          |               |               |
| LEFT JOIN      | `LEFT JOIN`                 | `how="left"`              | `LEFT JOIN`                 | `how="left"`                                     |               |               |
| ANTI JOIN      | `NOT IN`                    | `~isin()`                 | `id NOT IN`                 | `~df["id"].isin(df2["id"])`                      |               |               |
| UNION ALL      | `UNION ALL`                 | `concat()`                | see below                   | see below                                        |               |               |
| UNION          | `UNION`                     | `concat + distinct`       | see below                   | see below                                        |               |               |
| LIMIT          | `LIMIT 5`                   | `head()`                  | `LIMIT 5`                   | `df.head(5)`                                     |               |               |

| WINDOW       | SQL            | PANDAS                 | SQL EXAMPLE         | PANDAS EXAMPLE        |
| ------------ | -------------- | ---------------------- | ------------------- | --------------------- |
| PARTITION BY | `PARTITION BY` | `groupby()`            | `PARTITION BY dept` | `groupby("dept")`     |
| ORDER BY     | `ORDER BY`     | `sort_values()`        | `ORDER BY date`     | `sort_values("date")` |
| ROW_NUMBER   | `ROW_NUMBER()` | `cumcount()+1`         | see below           | see below             |
| RANK         | `RANK()`       | `rank()`               | see below           | see below             |
| DENSE_RANK   | `DENSE_RANK()` | `rank(method="dense")` | see below           | see below             |
| LAG          | `LAG(x)`       | `shift(1)`             | see below           | see below             |
| LEAD         | `LEAD(x)`      | `shift(-1)`            | see below           | see below             |
| RUNNING SUM  | `SUM(x) OVER`  | `cumsum()`             | see below           | see below             |
| ROLLING AVG  | `AVG(x) OVER`  | `rolling()`            | see below           | see below             |

 ---------------------  ---------------------  ---------------------  ---------------------  ---------------------  --------------------- 
df = df.sort_values(
    ["dept", "date"], 
    ascending=[True, False]
)

df["row_number"] = df.groupby("dept").cumcount() + 1

df["rank"] = df.groupby("dept")["salary"].rank(
    method="dense", ascending=False
)

df["lag_salary"] = df.groupby("dept")["salary"].shift(1)

df["running_sum"] = df.groupby("dept")["salary"].cumsum()


df["result"] = np.where(df["score"] >= 50, "PASS", "FAIL")


df["grade"] = np.select(
    [
        df["score"] >= 85,
        df["score"] >= 70,
        df["score"] >= 50
    ],
    ["A", "B", "C"],
    default="F"
)
users["name"] = users["name"].str[0].str.upper() + users["name"].str[1:].str.lower()

valid = df[df["prefix_name"].str.match(r"^[A-Za-z][A-Za-z0-9_.-]*$")]
| Part | Meaning                                    |
| ---- | ------------------------------------------ |
| `^`  | start of string                            |
| `.*` | any character, any number (including zero) |
| `.`  | exactly one character                      |
| `$`  | end of string                              |


 ---------------------  ---------------------  ---------------------  ---------------------  ---------------------  --------------------- 
MEMORY HOOK (REMEMBER THIS)

LIKE → .str.contains / startswith / endswith

DISTINCT → .drop_duplicates()

UNION ALL → pd.concat()

UNION → pd.concat().drop_duplicates()



```python
# =========================
# UNIVERSAL PANDAS TEMPLATE
# =========================
result = (
    df.loc[condition, cols]
      .assign(new_col=lambda x: ...)
      .groupby(keys, as_index=False)
      .agg(metrics)
      .sort_values(order)
)

result = (
    df1
    .loc[condition, ["id", "k1", "k2", "qty", "price", "date"]]   # early select
    .merge(df2, left_on=["k1","k2"], right_on=["fk1","fk2"],how="left",suffixes=("_left", "_right"))  or( suffixes=("", "_dept"))  all columns will be suffixed 
    .assign(revenue=lambda x: x["qty"] * x["price"])
    .groupby(["id","date"], as_index=False)
    .agg(total_revenue=("revenue","sum"))
    .sort_values("id")
    [["id", "date", "total_revenue"]]   
)


import numpy as np

result = (
    df
    # WHERE (multiple conditions)
    .loc[
        ((df["a"] > 10) & (df["b"] == "X")) | (df["c"] < 5),
        ["id", "country", "product", "qty", "price", "date"]
    ]

    # DERIVED COLUMNS / CASE
    .assign(
        revenue=lambda x: x["qty"] * x["price"],
        flag=lambda x: np.where(x["qty"] > 5, "HIGH", "LOW")
    )

    # GROUP BY (multiple keys)
    .groupby(["country", "product", "date"], as_index=False)

    # AGGREGATIONS (multiple metrics)
    .agg(
        total_revenue=("revenue", "sum"),
        avg_qty=("qty", "mean"),
        min_price=("price", "min"),
        max_price=("price", "max")
    )

    # WINDOW FUNCTIONS (PARTITION BY / ORDER BY)
    .sort_values(["country", "date"])
    .assign(
        running_revenue=lambda x: x.groupby("country")["total_revenue"].cumsum(),
        row_number=lambda x: x.groupby("country").cumcount() + 1,
        rank=lambda x: x.groupby("country")["total_revenue"]
                         .rank(method="dense", ascending=False),
        lag_revenue=lambda x: x.groupby("country")["total_revenue"].shift(1)
    )

    # ORDER BY (multiple cols, mixed order)
    .sort_values(
        by=["country", "total_revenue"],
        ascending=[True, False]
    )
    .rename(columns={"author_id": "id"})
    .drop_duplicates()
    # FINAL SELECT (after GROUP + WINDOW)
    [["country", "product", "date",
      "total_revenue", "avg_qty",
      "running_revenue", "rank"]]
)
```
```python
# =========================
# UNIVERSAL PANDAS TEMPLATE
# (FILTER + JOIN + RENAME + AGG + WINDOW + SORT + SELECT)
# =========================

result = (
    df1
    # WHERE (multiple conditions)
    .loc[
        ((df1["a"] > 10) & (df1["b"] == "X")) | (df1["c"] < 5),
        ["id", "k1", "k2", "qty", "price", "date"]
    ]

    # JOIN (different key names, multiple keys)
    .merge(
        df2.loc[
            (df2["flag"] == "Y") & (df2["type"].isin(["T1", "T2"])),
            ["fk1", "fk2", "attr"]
        ],
        left_on=["k1", "k2"],
        right_on=["fk1", "fk2"],
        how="left"
    )

    # RENAME (alias columns)
    .rename(columns={
        "id": "entity_id",
        "attr": "attribute"
    })

    # DERIVED COLUMNS / CASE
    .assign(
        revenue=lambda x: x["qty"] * x["price"],
        bucket=lambda x: np.where(x["qty"] > 5, "HIGH", "LOW")
    )

    # GROUP BY (multiple keys)
    .groupby(["entity_id", "date"], as_index=False)

    # AGG (multiple metrics)
    .agg(
        total_revenue=("revenue", "sum"),
        avg_qty=("qty", "mean"),
        min_price=("price", "min"),
        max_price=("price", "max")
    )

    # WINDOW (PARTITION BY + ORDER BY)
    .sort_values(["entity_id", "date"])
    .assign(
        running_revenue=lambda x: x.groupby("entity_id")["total_revenue"].cumsum(),
        row_number=lambda x: x.groupby("entity_id").cumcount() + 1,
        rank=lambda x: x.groupby("entity_id")["total_revenue"]
                         .rank(method="dense", ascending=False),
        lag_revenue=lambda x: x.groupby("entity_id")["total_revenue"].shift(1)
    )

    # ORDER BY (multi-column, mixed ASC/DESC)
    .sort_values(
        by=["entity_id", "total_revenue"],
        ascending=[True, False]
    )

    # FINAL SELECT (output columns)
    [["entity_id", "date", "total_revenue", "avg_qty",
      "running_revenue", "rank", "lag_revenue"]]
)
```


df[df["col"].str.contains("abc", case=False)]
df[df["col"].str.startswith("A")]
df[df["col"].str.endswith("son")]




1.Write a solution to find all customers who never order anything.

import pandas as pd

def find_customers(customers, orders):
    return (
        customers.loc[
            ~customers["id"].isin(orders["customerId"]),
            ["name"]
        ]
        .rename(columns={"name": "Customers"})
    )
  2.Write a solution to find the name, population, and area of the big countries.
  import pandas as pd

def big_countries(world: pd.DataFrame) -> pd.DataFrame:
    # Apply business rule:
    # A country is big if area >= 3,000,000 OR population >= 25,000,000
    result = world.loc[
        (world["area"] >= 3000000) |
        (world["population"] >= 25000000)
    , ["name", "population", "area"]] 

    return result

    import pandas as pd
3.Write a solution to find all the authors that viewed at least one of their own articles.
def article_views(views: pd.DataFrame) -> pd.DataFrame:
    return (
        views.loc[
            views["author_id"] == views["viewer_id"],
            ["author_id"]
        ]
        .rename(columns={"author_id": "id"})
        .drop_duplicates()
        .sort_values(["id"])
    )

4.. Nth Highest Salary
    def nth_highest_salary(employee: pd.DataFrame, n: int) -> pd.DataFrame:
    salaries = (
        employee[["salary"]]
        .drop_duplicates()
        .sort_values("salary", ascending=False)
    )

    col_name = f"getNthHighestSalary({n})"

    if len(salaries) < n:
        return pd.DataFrame({col_name: [None]})

    return pd.DataFrame({
        col_name: [salaries.iloc[n - 1]["salary"]]
    })

5.a Department Highest Salary
import pandas as pd

def department_highest_salary(employee: pd.DataFrame, department: pd.DataFrame) -> pd.DataFrame:
    df = employee.merge(
        department,
        left_on="departmentId",
        right_on="id",
        how="inner",
        suffixes=("", "_dept")
    )

    df["rank"] = (
        df.groupby("name_dept")["salary"]
          .rank(method="dense", ascending=False)
    )

    result = df.loc[
        df["rank"] == 1,
        ["name_dept", "name", "salary"]
    ].rename(columns={
        "name_dept": "Department",
        "name": "Employee",
        "salary": "Salary"
    })

    return result
5.b 
 def department_highest_salary(employee, department):
    df = employee.merge(
        department,
        left_on="departmentId",
        right_on="id",
        how="inner",
        suffixes=("_emp", "_dept")
    )

    df["max_salary"] = df.groupby("name_dept")["salary"].transform("max")

    return df.loc[
        df["salary"] == df["max_salary"],
        ["name_dept", "name_emp", "salary"]
    ].rename(columns={
        "name_dept": "Department",
        "name_emp": "Employee",
        "salary": "Salary"
    })

5.c
import pandas as pd

def department_highest_salary(employee: pd.DataFrame, department: pd.DataFrame) -> pd.DataFrame:
    # Join with explicit suffixes
    df = employee.merge(
        department,
        left_on="departmentId",
        right_on="id",
        how="inner",
        suffixes=("_emp", "_dept")
    )

    # Compute max salary per department
    max_salary = (
        df.groupby("name_dept", as_index=False)
          .agg(max_salary=("salary", "max"))
    )

    # Filter employees with max salary
    result = (
        df.merge(max_salary, on="name_dept", how="inner")
          .loc[
              lambda x: x["salary"] == x["max_salary"],
              ["name_dept", "name_emp", "salary"]
          ]
          .rename(columns={
              "name_dept": "Department",
              "name_emp": "Employee",
              "salary": "Salary"
          })
    )

    return result
filtered = df.merge(max_salary, on="name_dept", how="inner")
filtered = filtered[filtered["salary"] == filtered["max_salary"]]

result = filtered[["name_dept", "name_emp", "salary"]].rename(columns={
    "name_dept": "Department",
    "name_emp": "Employee",
    "salary": "Salary"
})

6. Rank Scores
def order_scores(scores: pd.DataFrame) -> pd.DataFrame:
    scores["rank"] =  scores["score"].rank(method ="dense",ascending = False)

    result = scores [["score","rank"]].sort_values(["rank"])
 
    return result


import pandas as pd
7.Managers with at Least 5 Direct Reports
def find_managers(employee: pd.DataFrame) -> pd.DataFrame:
    join_df = (
        employee
        .merge(employee ,left_on =["managerId"],right_on =["id"],suffixes =("","_mgr"))
        .groupby("name_mgr", as_index=False)
        .agg(emp_count =("id","count"))
        .loc[lambda x: x["emp_count"] >= 5, ["name_mgr"]]
        .rename(columns={"name_mgr":"name"})
    )
    return join_df
8.Count Salary Categories
import pandas as pd
import numpy as np

def count_salary_categories(accounts: pd.DataFrame) -> pd.DataFrame:
    accounts["category"] = np.select(
        [accounts['income'] < 20000,
        (accounts['income'] >= 20000) & (accounts['income'] <= 50000),
        accounts['income'] > 50000],
        ["Low_salary","Average Salary","High Salary"]
    )
    result  = (accounts
    .groupby(["category"])
    .agg(accounts_count = ("account_id","count"))
    .sort_values(["category"],ascending = True)
    )
    return result 
