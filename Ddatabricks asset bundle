https://www.youtube.com/watch?v=q2hDLpsJfmE
 

 | Source             | Prefix                    | Automatic? | Example                        |
| ------------------ | ------------------------- | ---------- | ------------------------------ |
| Workspace Metadata | `workspace.*`             | Auto       | `${workspace.host}`            |
| Target Config      | `targets.<env>.*`         | Auto       | `${targets.dev.spark_version}` |
| User Variables     | `var.*`                   | Manual     | `${var.cluster_size}`          |
| Env Variables      | `env.*`                   | Shell/CICD | `${env.BRANCH_NAME}`           |
| Bundle Metadata    | `bundle.*`                | Auto       | `${bundle.name}`               |
| Resource Metadata  | `resources.<type>.<name>` | Auto       | `${resources.jobs.myjob.id}`   |

 databricks-project/
│
├── databricks.yml               # Root bundle configuration
├── variables.yml                # Global variables (prefixes, paths, etc.)
├── secrets.yml                  # Secret / sensitive variables
│
├── targets/                     # Environment-specific configs
│   ├── dev.yml
│   ├── test.yml
│   └── prod.yml
│
├── resources/                   # Databricks-managed resources
│   ├── clusters/                # Cluster definitions
│   │   ├── dev_cluster.yml
│   │   └── prod_cluster.yml
│   │
│   ├── jobs/                    # Jobs that orchestrate notebooks/scripts
│   │   ├── etl_job.yml
│   │   ├── analytics_job.yml
│   │   └── backup_job.yml       # Example job calling DB backup script
│   │
│   ├── pipelines/               # Databricks Workflows / Delta Live Tables
│   │   ├── daily_pipeline.yml
│   │   └── weekly_pipeline.yml
│   │
│   └── notebooks/               # Notebooks executed by Jobs or Pipelines
│       ├── load_data_notebook.py
│       ├── transform_data_notebook.py
│       └── analytics_notebook.py
│
├── src/                         # Source code / SQL / helper modules
│   ├── notebooks/               # Raw notebook sources (optional)
│   │   ├── demo_notebook.ipynb
│   │   └── temp_notebook.ipynb
│   │
│   ├── python/                  # Python scripts (utils, helpers, DB backup)
│   │   ├── utils.py
│   │   ├── db_backup.py
│   │   └── data_validation.py
│   │
│   ├── notebooks_lib/           # Python modules imported in notebooks
│   │   └── helper_functions.py
│   │
│   └── sql/                     # SQL scripts
│       ├── ddl/                 # Table, view, UDF definitions
│       │   ├── tables/
│       │   │   ├── customer_table.sql
│       │   │   ├── orders_table.sql
│       │   │   └── sales_table.sql
│       │   ├── views/
│       │   │   ├── customer_view.sql
│       │   │   └── order_summary_view.sql
│       │   └── udfs/
│       │       └── calculate_discount.sql
│       │
│       └── dml/                 # Insert / update / transformation scripts
│           ├── insert_customer.sql
│           ├── update_orders.sql
│           └── aggregate_sales.sql
│
└── tests/                       # Optional QA / testing scripts
    ├── test_etl.py
    └── test_sql_queries.sql


No — the folder names **don’t have to be exactly the ones I used**, but Databricks Bundles **expects certain conventions for specific types of files**. Some are flexible; others are required. Here’s a clear breakdown:

---

# ✅ **1. Required / fixed names**

| File / Folder           | Must it be named this?                   | Notes                                                                                                   |
| ----------------------- | ---------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| `databricks.yml`        | ✅ Yes                                    | Root-level, mandatory entry point                                                                       |
| `targets/`              | ✅ Yes                                    | Folder for environment YAMLs (`dev.yml`, `prod.yml`)                                                    |
| `variables.yml`         | ❌ Optional, but if used, must be at root | Can be renamed but then references in `databricks.yml` must point to the correct file using `includes:` |
| `resources/`            | ❌ Optional                               | Can rename, but references inside `databricks.yml` must match                                           |
| `/resources/jobs/`      | ❌ Optional                               | Can rename, but job references inside bundle must match                                                 |
| `/resources/clusters/`  | ❌ Optional                               | Same as above                                                                                           |
| `/resources/pipelines/` | ❌ Optional                               | Same as above                                                                                           |

---

# ✅ **2. Flexible / can be renamed**

| Folder / File   | Notes                                                                                                                                  |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------- |
| `src/`          | Can be `code/`, `scripts/`, or anything, as long as you don’t put bundle-managed YAMLs here. Only raw code, notebooks, or SQL scripts. |
| `/src/sql/ddl/` | Can be renamed; just keep consistent with your workflow                                                                                |
| `/src/python/`  | Can be renamed; update notebook imports accordingly                                                                                    |
| `/tests/`       | Can be renamed; only affects your local QA/testing                                                                                     |

---

# ⚠️ **Important constraints**

1. **Environment YAMLs (`dev.yml`, etc.) must be under the folder you register in `databricks.yml`** — the bundle engine only scans the folder specified.
2. **Variables YAML** must be included in `databricks.yml` if not named `variables.yml`.
3. **Jobs/pipelines/notebooks references** inside `databricks.yml` must match the folder names.

---

# ✅ **Example with renamed folders**

You can do:

```
my-project/
├── databricks.yml
├── config/                   # renamed from targets/
│   ├── dev.yml
│   └── prod.yml
├── globals.yml               # renamed from variables.yml
├── infra/                    # renamed from resources/
│   ├── jobs/
│   ├── clusters/
│   └── notebooks/
└── code/                     # renamed from src/
    ├── sql/
    └── python/
```

In this case, your `databricks.yml` must point to the correct folders:

```yaml
includes:
  - config/*.yml
  - globals.yml
  - infra/jobs/*.yml
  - infra/clusters/*.yml
```

---

So in short:

* **Fixed names**: `databricks.yml`, `targets/` (unless you override in `includes`)
* **Flexible**: `resources/`, `src/`, `variables.yml`, `tests/` — can rename if you update references

                   databricks.yml
                         |
                         v
             Includes: globals.yml, secrets.yml
                         |
        ---------------------------------------------
        |                                           |
   globals.yml                                   secrets.yml
   -----------                                   -----------
   prefix: "dev-myproject"      <--- duplicate ---> prefix: "secret-prefix"
   region: "australia-southeast1"             db_password: "mypassword"
   default_cluster: "small-job-cluster"
        |
        v
    Combined ${var.*} Namespace:
    ---------------------------
    prefix        -> "secret-prefix"   # last included file wins
    region        -> "australia-southeast1"
    default_cluster -> "small-job-cluster"
    db_password   -> "mypassword"
